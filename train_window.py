import pandas as pd
import numpy as np
import torch
from torch import nn
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
from tkinter import messagebox
from tkinter import ttk
import methods.primal_layers_model as unn

class TrainWindow:
    def __init__(self, root, name, u_ub, u_lb, z_ub, z_lb, state_vectors, horizon_length):
        self.root = root
        self.u_ub = u_ub
        self.u_lb = u_lb
        self.z_ub = z_ub
        self.z_lb = z_lb
        self.state_vectors = state_vectors
        self.horizon_length = horizon_length
        self.root.geometry("200x200")

        # Label for setting max epochs
        ttk.Label(self.root, text="Set the number of epochs:").pack(pady=10)
        
        # Entry to input the number of epochs
        self.epochs_entry = ttk.Entry(self.root)
        self.epochs_entry.pack(pady=5)
        self.epochs_entry.insert(0, "50")  # Default value is 50

        # Adding the button to start the training
        start_train_button = ttk.Button(self.root, text="Start Training", command=self.start_training)
        start_train_button.pack(pady=20)

    def start_training(self):
        """Starts the training process."""
        try:
            # Get the number of epochs from the input field
            num_epochs = int(self.epochs_entry.get())

            # Load the data generated by the previous window (CSV file)
            data = pd.read_csv('data/generated_data.csv')
            print("Data loaded successfully!")

            # Extract state vectors (z0) and control law (u) from the CSV file
            X = data['z0'].apply(lambda x: np.fromstring(x[1:-1], sep=' '))  # Converting string to numpy array
            Y = data['u'].apply(lambda x: np.fromstring(x[1:-1], sep=' '))  # Converting string to numpy array

            # Convert data to numpy arrays
            X = np.vstack(X.values)  # Stack rows of state vectors
            Y = np.vstack(Y.values)  # Stack rows of control laws

            # Split data into training and testing sets
            X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

            # Convert data to PyTorch tensors
            X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
            Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)
            X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
            Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32)

            # Create DataLoader for batching
            train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)
            test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)
            train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
            test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
            
            u_dim = self.u_lb.shape[0] * self.horizon_length
            z_dim = self.z_lb.shape[0]
            if self.state_vectors == 1:
                # Define the neural network model for Primal Dual
                model = nn.Sequential(
                    unn.PDfirstLayer(u_dim, 2*u_dim + z_dim, z_dim, self.horizon_length, self.u_lb, self.u_ub, self.z_lb, self.z_ub),  # First layer (state vector size to 128 neurons)
                    unn.PDunfoldingLayer(u_dim, 2*u_dim + z_dim,z_dim, self.horizon_length, self.u_lb, self.u_ub, self.z_lb, self.z_ub),      # Hidden layer (128 neurons to 64 neurons)
                    unn.PDunfoldingLayer(u_dim, 2*u_dim + z_dim,z_dim, self.horizon_length, self.u_lb, self.u_ub, self.z_lb, self.z_ub),      # Hidden layer (128 neurons to 64 neurons)
                    unn.PDunfoldingLayer(u_dim, 2*u_dim + z_dim,z_dim, self.horizon_length, self.u_lb, self.u_ub, self.z_lb, self.z_ub),      # Hidden layer (128 neurons to 64 neurons)
                    unn.PDunfoldingLayer(u_dim, 2*u_dim + z_dim,z_dim, self.horizon_length, self.u_lb, self.u_ub, self.z_lb, self.z_ub),      # Hidden layer (128 neurons to 64 neurons)
                    unn.outLayer(2*u_dim + z_dim, u_dim)  # Output layer (control law size)
                    )
            else:
                model = nn.Sequential(    
                        unn.PfirstLayer(u_dim, 2*u_dim + z_dim,z_dim, self.u_lb, self.u_ub),  # First layer (state vector size to 128 neurons)
                        unn.PunfoldingLayer(u_dim, 2*u_dim + z_dim,z_dim,  self.u_lb, self.u_ub),      # Hidden layer (128 neurons to 64 neurons)
                        unn.PunfoldingLayer(u_dim, 2*u_dim + z_dim,z_dim,  self.u_lb, self.u_ub),      # Hidden layer (128 neurons to 64 neurons)
                        unn.PunfoldingLayer(u_dim, 2*u_dim + z_dim,z_dim,  self.u_lb, self.u_ub),      # Hidden layer (128 neurons to 64 neurons)
                        unn.PunfoldingLayer(u_dim, 2*u_dim + z_dim,z_dim, self.u_lb, self.u_ub),      # Hidden layer (128 neurons to 64 neurons)
                        unn.outLayer(2*u_dim + z_dim, u_dim)  # Output layer (control law size)
                        )

            # Define the loss function and optimizer
            criterion = nn.MSELoss()  # Mean Squared Error loss for regression
            optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

            # Train the model
            for epoch in range(num_epochs):
                model.train()
                running_loss = 0.0
                for i, (inputs, targets) in enumerate(train_loader):
                    optimizer.zero_grad()  # Zero the gradients
                    outputs = model(inputs)  # Forward pass
                    loss = criterion(outputs, targets)  # Calculate loss
                    loss.backward()  # Backward pass
                    optimizer.step()  # Update weights

                    running_loss += loss.item()

                # Print training statistics every 10 epochs
                if (epoch + 1) % 10 == 0:
                    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}")

            # Evaluate the model on the test data
            model.eval()
            with torch.no_grad():
                test_loss = 0.0
                for inputs, targets in test_loader:
                    outputs = model(inputs)
                    loss = criterion(outputs, targets)
                    test_loss += loss.item()

                print(f"Test Loss: {test_loss / len(test_loader):.4f}")

            messagebox.showinfo("Training Complete", "Training completed successfully!")
        
        except Exception as e:
            messagebox.showerror("Error", f"An error occurred during training: {str(e)}")
